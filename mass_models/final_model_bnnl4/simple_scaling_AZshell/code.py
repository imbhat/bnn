# -*- coding: utf-8 -*-
"""claude_numpyro_nuclear_masses.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vtFloNEJprPjXcWKh161sh0FG9KlEoJ_
"""

# !pip install numpyro

import numpy as np
import pandas as pd
import jax.numpy as jnp
import jax
import numpyro
import numpyro.distributions as dist
from numpyro.infer import NUTS, MCMC, Predictive
from jax import random
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, QuantileTransformer
import arviz as az
import matplotlib.pyplot as plt

# Set a random seed for reproducibility
RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)
numpyro.set_host_device_count(4)  # Adjust based on your hardware

# Load and preprocess data
df = pd.read_csv('data.csv')  # Replace with your data loading method

target_feature = 'ws4_residuals'

input_features = ['Z', 'A', 'pairing', 'shell']

neuron_number = 28

features_to_scale = ['Z', 'A', 'shell']

# Split the dataset into training and validation sets (80% training, 20% validation)
train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, shuffle=True)

Z_train, A_train, Z_test, A_test = train_df['Z'], train_df['A'], val_df['Z'], val_df['A']


def scale_standardize(train_df, val_df, features_to_scale=features_to_scale):
    scaler = StandardScaler()

    try:
        if features_to_scale:
            train_df[features_to_scale] = scaler.fit_transform(train_df[features_to_scale])
            val_df[features_to_scale] = scaler.transform(val_df[features_to_scale])
        else:
            print("features_to_scale is empty. Returning DataFrames as they are.") 
    except (ValueError, KeyError) as e:  
        print(f"An error occurred during scaling: {e}")

    return train_df, val_df

train_df, val_df = scale_standardize(train_df, val_df)


# Convert to JAX arrays
X_train_jax = jnp.array(train_df[input_features])
y_train_jax = jnp.array(train_df[target_feature])
X_test_jax = jnp.array(val_df[input_features])
y_test_jax = jnp.array(val_df[target_feature])

def bnn(X, y=None, hidden_size=neuron_number):  # Define hidden_size here
    input_size = X.shape[1]

    # Weight and bias precisions for the first layer
    fc1_weight_precision = numpyro.sample("fc1_weight_precision", dist.Gamma(1.0, 1.0))
    fc1_weight = numpyro.sample("fc1_weight", dist.Normal(0., jnp.power(fc1_weight_precision, -0.5)).expand([hidden_size, input_size]).to_event(2))
    fc1_bias_precision = numpyro.sample("fc1_bias_precision", dist.Gamma(1.0, 1.0))
    fc1_bias = numpyro.sample("fc1_bias", dist.Normal(0., jnp.power(fc1_bias_precision, -0.5)).expand([hidden_size]).to_event(1))

    # Weight and bias precisions for the second layer
    fc2_weight_precision = numpyro.sample("fc2_weight_precision", dist.Gamma(1.0, 1.0))
    fc2_weight = numpyro.sample("fc2_weight", dist.Normal(0., jnp.power(fc2_weight_precision, -0.5)).expand([1, hidden_size]).to_event(2))
    fc2_bias_precision = numpyro.sample("fc2_bias_precision", dist.Gamma(1.0, 1.0))
    fc2_bias = numpyro.sample("fc2_bias", dist.Normal(0., jnp.power(fc2_bias_precision, -0.5)).expand([1]).to_event(1))

    # Noise precision
    noise_precision = numpyro.sample("noise_precision", dist.Gamma(1.0, 1.0))

    # Model structure
    hidden = jnp.tanh(jnp.dot(X, fc1_weight.T) + fc1_bias)
    output = jnp.dot(hidden, fc2_weight.T) + fc2_bias
    output = output.squeeze()

    # Likelihood
    sigma = 1.0 / jnp.sqrt(noise_precision)
    with numpyro.plate("data", X.shape[0]):
        numpyro.sample("obs", dist.Normal(output, sigma), obs=y)
    return output

# Set up the NUTS sampler and MCMC
nuts_kernel = NUTS(bnn, target_accept_prob=0.9)
mcmc = MCMC(nuts_kernel, num_warmup=2000, num_samples=4000, num_chains=4)

# Run the MCMC
mcmc.run(random.PRNGKey(0), X_train_jax, y_train_jax)

# Model and chain statistics summary
idata = az.from_numpyro(mcmc)
az.summary(idata).to_csv('stat.csv')

# Extract posterior samples
posterior_samples = mcmc.get_samples()

# Save the samples (which represent your trained model parameters)
jnp.savez('ws4_residuals_model.npz', **posterior_samples)

# To load the saved parameters later
with jnp.load('ws4_residuals_model.npz') as data:
    loaded_samples = dict(data)

# Create a predictive object
predictive = Predictive(bnn, posterior_samples=loaded_samples)

# Get predictive samples for train and test sets (assuming you have them)
predictive_samples_train = predictive(jax.random.PRNGKey(0), X_train_jax)['obs']
predictive_samples_test = predictive(jax.random.PRNGKey(1), X_test_jax)['obs']

# Calculate means and standard deviations for uncertainties
mean_train = jnp.mean(predictive_samples_train, axis=0)
std_train = jnp.std(predictive_samples_train, axis=0)
mean_test = jnp.mean(predictive_samples_test, axis=0)
std_test = jnp.std(predictive_samples_test, axis=0)


# Predict the masses of the training set
predicted_mass_train = train_df['Mth_ws4'].values + mean_train

# Predict the masses of the test set
predicted_mass_test = val_df['Mth_ws4'].values + mean_test

import matplotlib.pyplot as plt

# Function to create and save residual plots
def plot_residuals(x, predicted_residuals, actual_residuals, xlabel, title, filename):
    plt.figure(figsize=(10, 6))
    
    plt.scatter(x, predicted_residuals, label="Predicted Residuals", color="blue", alpha=0.5)
    plt.scatter(x, actual_residuals, label="Actual Residuals", color="red", alpha=0.5)
    
    plt.xlabel(xlabel)
    plt.ylabel("Residuals (MeV)")
    plt.title(title)
    plt.legend()
    plt.grid(True)
    
    plt.savefig(filename, format='pdf')

# Function to create and save mass plots
def plot_masses(x, predicted_mass, actual_mass, xlabel, title, filename):
    plt.figure(figsize=(10, 6))
    
    plt.scatter(x, predicted_mass, label="Predicted Masses", color="blue", alpha=0.5)
    plt.scatter(x, actual_mass, label="Experimental Masses", color="red", alpha=0.5)
    
    plt.xlabel(xlabel)
    plt.ylabel("Mass (MeV)")
    plt.title(title)
    plt.legend()
    plt.grid(True)
    
    plt.savefig(filename, format='pdf')


# Call functions for residuals plots (Training Set)
plot_residuals(Z_train, mean_train, train_df['ws4_residuals'], 
               "Z", "Training Set: Predicted vs Actual Residuals", 
               "training_residuals_vs_Z.pdf")

plot_residuals(A_train, mean_train, train_df['ws4_residuals'], 
               "A", "Training Set: Predicted vs Actual Residuals", 
               "training_residuals_vs_A.pdf")

# Call functions for residuals plots (Validation Set)
plot_residuals(Z_test, mean_test, val_df['ws4_residuals'], 
               "Z", "Validation Set: Predicted vs Actual Residuals", 
               "test_residuals_vs_Z.pdf")

plot_residuals(A_test, mean_test, val_df['ws4_residuals'], 
               "A", "Validation Set: Predicted vs Actual Residuals", 
               "test_residuals_vs_A.pdf")


# Call functions for mass plots (Training Set)
plot_masses(Z_train, predicted_mass_train, train_df['Mexp'], 
            "Z", "Training Set: Predicted vs Experimental Masses", 
            "training_masses_vs_Z.pdf")

plot_masses(A_train, predicted_mass_train, train_df['Mexp'], 
            "A", "Training Set: Predicted vs Experimental Masses", 
            "training_masses_vs_A.pdf")

# Call functions for mass plots (Validation Set)
plot_masses(Z_test, predicted_mass_test, val_df['Mexp'], 
            "Z", "Validation Set: Predicted vs Experimental Masses", 
            "test_masses_vs_Z.pdf")

plot_masses(A_test, predicted_mass_test, val_df['Mexp'], 
            "A", "Validation Set: Predicted vs Experimental Masses", 
            "test_masses_vs_A.pdf")


# Save the RMSDs to a file
with open('output.txt', 'w') as f:
    f.write(f"Original model RMSD for training dataset was {train_df[target_feature].std()}\n")
    f.write(f"BNN-l4 model RMSD for training set is {(train_df['Mexp'] -predicted_mass_train).std()}\n")
    f.write(f"Original model RMSD for test dataset was {val_df[target_feature].std()}\n")
    f.write(f"BNN-l4 model RMSD for test set {(val_df['Mexp'] -predicted_mass_test).std()}\n")

